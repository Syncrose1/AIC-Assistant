/**
 * TTS Emotion Adapters - Convert canonical emotions to TTS-specific formats
 *
 * Supports:
 * - Fish Speech V1.5 (tag-based)
 * - Qwen3-TTS (natural language)
 * - Basic TTS (strips emotions)
 */

import type { EmotionEmoji, EmotionMarker } from '@airi-mods/animation-core'
import { EMOTION_NAMES } from '@airi-mods/animation-core'

/**
 * TTS emotion adapter interface
 */
export interface TtsEmotionAdapter {
  /** TTS system name for identification */
  readonly name: string

  /** Check if this TTS supports emotions */
  supportsEmotions(): boolean

  /** Convert canonical format to TTS-specific format */
  convertText(text: string, emotions: EmotionMarker[]): string
}

/**
 * Fish Speech V1.5 Emotion Adapter
 *
 * Converts [EMOTION:ğŸ˜Š] â†’ (happy)
 *
 * Fish Speech uses inline tags: (emotion)
 * Tags are inserted at emotion positions.
 */
export class FishSpeechAdapter implements TtsEmotionAdapter {
  readonly name = 'fish-speech'

  supportsEmotions(): boolean {
    return true
  }

  convertText(text: string, emotions: EmotionMarker[]): string {
    if (emotions.length === 0) return text

    // Sort emotions by position (descending) to insert tags back-to-front
    // This prevents position shifts during insertion
    const sorted = [...emotions].sort((a, b) => b.position - a.position)

    let result = text
    for (const emotion of sorted) {
      const tag = this.emojiToFishTag(emotion.emotion)
      // Insert tag at position
      result = result.slice(0, emotion.position) + `(${tag}) ` + result.slice(emotion.position)
    }

    return result
  }

  /**
   * Map emoji to Fish Speech emotion tag.
   *
   * Fish Speech supports ~50+ tags. We map our 17 emotions to closest matches.
   * Reference: https://docs.fish.audio/developer-guide/core-features/emotions
   */
  private emojiToFishTag(emoji: EmotionEmoji): string {
    const mapping: Record<EmotionEmoji, string> = {
      // Positive
      'ğŸ˜Š': 'happy',
      'ğŸ¤©': 'excited',
      'ğŸ˜': 'confident',
      'ğŸ˜': 'smug',
      'ğŸ’ª': 'determined',
      // Reactive
      'ğŸ˜³': 'embarrassed',
      'ğŸ˜²': 'surprised',
      'ğŸ¤”': 'curious',
      'ğŸ‘€': 'interested',
      // Negative
      'ğŸ˜¤': 'frustrated',
      'ğŸ˜¢': 'sad',
      'ğŸ˜…': 'nervous',
      'ğŸ™„': 'disdainful',
      // Expressive
      'ğŸ’•': 'joyful',
      'ğŸ˜‚': 'laughing',
      'ğŸ”¥': 'passionate',
      'âœ¨': 'delighted',
      // Neutral
      'ğŸ˜': 'neutral',
    }

    return mapping[emoji] || 'neutral'
  }
}

/**
 * Qwen3-TTS 0.6B Emotion Adapter
 *
 * Converts [EMOTION:ğŸ˜Š] â†’ [TONE: warm and cheerful]
 *
 * Qwen3-TTS uses natural language instructions.
 * We prepend tone descriptions to guide the model.
 */
export class Qwen3Adapter implements TtsEmotionAdapter {
  readonly name = 'qwen3-tts'

  supportsEmotions(): boolean {
    return true
  }

  convertText(text: string, emotions: EmotionMarker[]): string {
    if (emotions.length === 0) return text

    // For Qwen3, we prepend tone instructions
    // Use the first/dominant emotion (or most frequent)
    const dominantEmotion = this.getDominantEmotion(emotions)
    const tone = this.emojiToNaturalLanguage(dominantEmotion)

    // Format: [TONE: warm and cheerful] Text here
    return `[TONE: ${tone}] ${text}`
  }

  /**
   * Get dominant emotion from markers.
   * Simple strategy: use first emotion.
   * Could be enhanced to find most frequent or weighted by position.
   */
  private getDominantEmotion(emotions: EmotionMarker[]): EmotionEmoji {
    return emotions[0].emotion
  }

  /**
   * Map emoji to natural language tone description for Qwen3.
   *
   * These descriptions guide the model's emotional expression.
   * Can be customized based on testing results.
   */
  private emojiToNaturalLanguage(emoji: EmotionEmoji): string {
    const mapping: Record<EmotionEmoji, string> = {
      // Positive
      'ğŸ˜Š': 'warm and cheerful',
      'ğŸ¤©': 'excited and energetic',
      'ğŸ˜': 'cool and confident',
      'ğŸ˜': 'playful and sly',
      'ğŸ’ª': 'determined and strong',
      // Reactive
      'ğŸ˜³': 'flustered and embarrassed',
      'ğŸ˜²': 'shocked and surprised',
      'ğŸ¤”': 'thoughtful and contemplative',
      'ğŸ‘€': 'curious and interested',
      // Negative
      'ğŸ˜¤': 'frustrated and intense',
      'ğŸ˜¢': 'sad and melancholic',
      'ğŸ˜…': 'nervous and awkward',
      'ğŸ™„': 'dismissive and annoyed',
      // Expressive
      'ğŸ’•': 'loving and adoring',
      'ğŸ˜‚': 'amused and laughing',
      'ğŸ”¥': 'passionate and intense',
      'âœ¨': 'bright and cheerful',
      // Neutral
      'ğŸ˜': 'neutral and calm',
    }

    return mapping[emoji] || 'naturally'
  }
}

/**
 * Basic TTS Adapter (No Emotion Support)
 *
 * Simply strips emotion tags and returns clean text.
 * Use for TTS systems that don't support emotional control.
 */
export class BasicTtsAdapter implements TtsEmotionAdapter {
  readonly name = 'basic-tts'

  supportsEmotions(): boolean {
    return false
  }

  convertText(text: string, emotions: EmotionMarker[]): string {
    // Just return clean text, emotions are ignored
    return text
  }
}

/**
 * Azure Neural TTS Adapter (Future)
 *
 * Would convert to SSML with <mstts:express-as> tags.
 * Placeholder for future implementation.
 */
export class AzureNeuralAdapter implements TtsEmotionAdapter {
  readonly name = 'azure-neural-tts'

  supportsEmotions(): boolean {
    return true
  }

  convertText(text: string, emotions: EmotionMarker[]): string {
    // TODO: Implement SSML conversion
    // <speak><mstts:express-as style="cheerful">Text</mstts:express-as></speak>
    return text
  }
}

/**
 * Create appropriate adapter based on TTS system name.
 */
export function createTtsAdapter(ttsSystem: string): TtsEmotionAdapter {
  switch (ttsSystem.toLowerCase()) {
    case 'fish-speech':
    case 'fish':
      return new FishSpeechAdapter()

    case 'qwen3-tts':
    case 'qwen3':
    case 'qwen':
      return new Qwen3Adapter()

    case 'azure-neural':
    case 'azure':
      return new AzureNeuralAdapter()

    default:
      return new BasicTtsAdapter()
  }
}
