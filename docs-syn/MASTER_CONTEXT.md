# AI-Assistant-Project: Master Context & Handover Document

**Last Updated**: 2026-01-28 (Jan 28, 2026)  
**Current Session**: Post-context-compaction recovery  
**Active Developer**: Raahat (User)  
**Platform**: CachyOS Linux (Hyprland), RTX 3060 12GB VRAM

---

## PROJECT OVERVIEW

Building a VTuber AI Personal Assistant on top of **Project AIRI** (TypeScript/Vue/Tauri monorepo). The project uses a **layered architecture** where our custom code lives in `airi-mods/` without modifying AIRI core.

### Architecture Philosophy
- **Product Independence**: Our code is self-contained
- **Clean Upgrades**: Can pull AIRI updates without merge conflicts
- **Local-First**: All ML/AI runs locally on RTX 3060

---

## CURRENT STATUS (Jan 28, 2026)

### âœ… COMPLETED PHASES

#### Phase 1: Environment Setup - COMPLETE
- CachyOS Linux with Hyprland
- Project AIRI cloned and running
- `airi-mods/` custom package structure established

#### Phase 2: VBridger Lip-Sync - COMPLETE âœ…
**Status**: Fully functional, mouth movements synchronized to TTS

**Implementation**:
- Package: `@airi-mods/lipsync-vbridger`
- Uses `MockProvider` for phoneme timing (temporary)
- 9-parameter lip-sync motion plugin
- Integrated with AIRI's motion manager

**Known Issues** (LOW PRIORITY):
- Idle mouth animations occasionally mix with lip-sync
- Solution planned: Hook into motion priority system

**Documentation**: `airi-mods/docs/VBRIDGER_TESTING_RESULTS.md`

#### Phase 3: ML-Based Emotion Detection - IN PROGRESS

**Current State**: WASM mode working, WebGPU disabled due to corruption

**Model Journey**:
1. âŒ **Attempt 1**: `j-hartmann/emotion-english-distilroberta-base` - No ONNX files
2. âŒ **Attempt 2**: `MicahB/roberta-base-go_emotions` (28 emotions) - Returns neutral for everything
3. âœ… **Attempt 3**: `MicahB/emotion_text_classifier` (7 emotions) - **CURRENTLY WORKING**
   - Trained on Friends TV dialogue
   - Works correctly with WASM mode
   - WebGPU produces corrupted results (fear for everything)

**CRITICAL DISCOVERY (Jan 28, 2026)**:
- WebGPU inference corrupted: "I am so happy!" â†’ fear (93%)
- WASM inference correct: "I am so happy!" â†’ joy (99%)
- Root cause: ONNX Runtime WebGPU backend bugs (known issue, see GitHub issues #18311, #23403)
- **Solution**: Force WASM mode via `device: 'wasm'` in pipeline config

**Current Implementation**:
- File: `airi-mods/packages/emotion-visual/src/emotion-ml-detector.ts`
- Device: WASM (CPU) - WebGPU disabled
- Performance: 50-200ms inference time
- Accuracy: Correctly detects joy/sadness/anger/surprise

**Text Preprocessing**: Removes markdown/code blocks before analysis

---

## ARCHITECTURE DECISION (Jan 28, 2026): Python Backend Service

### The Problem
Browser-based ML via ONNX Runtime is:
- âŒ Unreliable (WebGPU corruption bugs)
- âŒ Slow (60-180s WASM compilation)
- âŒ Limited (only ONNX-converted models)
- âŒ Memory hungry (~1GB in browser tab)

### The Solution
**Externalize all ML to a Python FastAPI backend service**

### Proposed Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AIRI Desktop App (Tauri)                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Vue Frontend                                            â”‚   â”‚
â”‚  â”‚  â€¢ Stage.vue (Live2D)                                    â”‚   â”‚
â”‚  â”‚  â€¢ Chat interface                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼ HTTP/JSON @ localhost:8000           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Python ML Service (Auto-started/killed by Tauri)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FastAPI Server                                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ POST /emotion/detect      â†’ 7 emotions              â”‚   â”‚
â”‚  â”‚  â”œâ”€ POST /align/phonemes      â†’ BFA phoneme timing     â”‚   â”‚
â”‚  â”‚  â”œâ”€ POST /tts/synthesize      â†’ Fish Speech            â”‚   â”‚
â”‚  â”‚  â”œâ”€ POST /asr/transcribe      â†’ Whisper                â”‚   â”‚
â”‚  â”‚  â””â”€ GET  /health             â†’ Service status          â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Models (loaded once on startup):                       â”‚   â”‚
â”‚  â”‚  â€¢ emotion: j-hartmann/emotion-english-distilroberta    â”‚   â”‚
â”‚  â”‚  â€¢ aligner: Bournemouth Forced Aligner (BFA)           â”‚   â”‚
â”‚  â”‚  â€¢ tts: Fish Speech V1.5 (planned)                     â”‚   â”‚
â”‚  â”‚  â€¢ asr: faster-whisper (planned)                       â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  VRAM: ~2-3GB total (loaded models)                    â”‚   â”‚
â”‚  â”‚  RAM: ~500MB service overhead                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Benefits Over Browser ONNX

| Aspect | Browser ONNX | Python Backend |
|--------|-------------|----------------|
| **Reliability** | âŒ WebGPU bugs, WASM quirks | âœ… PyTorch/CUDA just works |
| **Model Choice** | Only ONNX-converted models | Any HuggingFace model |
| **Emotion Model** | Broken Friends TV model | âœ… j-hartmann (7 emotions, works) |
| **Phoneme Timing** | âŒ Not available in browser | âœ… Bournemouth Forced Aligner |
| **Inference Speed** | ~800-4000ms (WASM) | ~20-50ms (CUDA) |
| **Memory** | ~1GB in browser tab | ~2.5GB dedicated service |
| **Startup Time** | 60-180s WASM compile | ~10s model load |

### Bournemouth Forced Aligner (BFA) - The Superior Choice

**Why BFA over Montreal Forced Aligner (MFA)**:
- **BFA**: 0.2s for 10s audio (240x faster!)
- **MFA**: 10s for 2s audio
- **BFA**: Real-time capable âœ…
- **BFA**: Contextless Universal Phoneme Encoder (CUPE)
- **BFA**: 80+ languages support
- **BFA**: PyTorch-based, easy integration

**Current VBridger Limitation**:
- Using `MockProvider` - fake phoneme timing based on heuristics
- **With BFA**: Real phoneme timing â†’ perfect lip-sync

---

## IMPLEMENTATION PLAN

### Phase 1: Python ML Backend Service (IMMEDIATE)

**Location**: `airi-mods/services/ml-backend/`

**Components**:
1. **FastAPI server** (`main.py`)
   - Health check endpoint
   - Emotion detection endpoint
   - Phoneme alignment endpoint (BFA)

2. **Model loaders** (`models/`)
   - `emotion.py` - j-hartmann emotion model
   - `aligner.py` - BFA wrapper

3. **Tauri integration** (`src-tauri/` modifications)
   - Spawn Python service on app startup
   - Kill service on app exit
   - Health check monitoring

4. **TypeScript client** (`packages/emotion-visual/src/client.ts`)
   - HTTP client for backend communication
   - Fallback to WASM if service unavailable

**Implementation Steps**:
1. Create Python virtual environment
2. Install dependencies (FastAPI, transformers, bournemouth-forced-aligner)
3. Implement emotion detection endpoint
4. Implement BFA phoneme alignment endpoint
5. Create Tauri service management
6. Update TypeScript client to use HTTP API
7. Test integration
8. Document thoroughly

### Phase 2: Frontend Integration

**Update packages**:
1. `@airi-mods/emotion-visual` - Use HTTP client instead of transformers.js
2. `@airi-mods/lipsync-vbridger` - Use BFA for real phoneme timing
3. Create fallback mechanisms

### Phase 3: TTS/ASR Internalization (FUTURE)

**Goal**: Replace `speaches` server with our integrated service
- Fish Speech V1.5 for TTS
- faster-whisper for ASR
- Single unified service

---

## TECHNICAL DETAILS

### Critical Knowledge

**1. WebGPU Corruption Issue**:
```typescript
// âŒ WRONG - Produces garbage results
pipelineConfig.device = 'webgpu'

// âœ… CORRECT - Force WASM
pipelineConfig.device = 'wasm'
```

**2. Cache Clearing**:
```typescript
// Must clear IndexedDB cache for fresh model download
const deleteRequest = indexedDB.deleteDatabase('transformers-cache')
```

**3. Device Options in Transformers.js v3**:
- `'webgpu'` - GPU via WebGPU (BROKEN for our model)
- `'wasm'` - CPU via WebAssembly (WORKING)
- `'cpu'` - NOT SUPPORTED (throws error)

**4. BFA Installation**:
```bash
pip install bournemouth-forced-aligner
# System dependencies:
apt-get install espeak-ng ffmpeg
```

### Current File Locations

**Emotion Detection**:
- `airi-mods/packages/emotion-visual/src/emotion-ml-detector.ts`
- `airi-mods/packages/emotion-visual/src/plugin.ts`

**VBridger Lip-Sync**:
- `airi-mods/packages/lipsync-vbridger/src/`
- Uses `MockProvider` temporarily

**Documentation**:
- `airi-mods/docs/EMOTION_DETECTION_IMPLEMENTATION.md`
- `airi-mods/docs/MASTER_CONTEXT.md` (this file)

---

## ğŸ§ª TESTING & DEBUGGING

### ML Backend Service Test Suite

**CRITICAL**: If debugging the ML backend service, **ALWAYS RUN TESTS FIRST**

**Location**: `airi-mods/services/ml-backend/tests/`

**Test Files**:
1. `scripts/test_service.py` - **Main diagnostic tool** (USE THIS FIRST)
2. `scripts/run_tests.sh` - Automated test runner
3. `tests/test_api.py` - PyTest suite
4. `tests/README.md` - Complete testing guide

**Quick Test Commands**:
```bash
cd airi-mods/services/ml-backend

# Full diagnostic (recommended)
python scripts/test_service.py

# Test specific component
python scripts/test_service.py --test health
python scripts/test_service.py --test emotion
python scripts/test_service.py --test performance

# Automated test run
bash scripts/run_tests.sh

# PyTest suite
python -m pytest tests/test_api.py -v
```

**What Tests Check**:
- âœ… Service health and availability
- âœ… All API endpoints functionality
- âœ… Emotion detection accuracy (7 emotions)
- âœ… Error handling and edge cases
- âœ… Performance benchmarks (<100ms requirement)
- âœ… Stability under load (100 requests)
- âœ… Resource usage monitoring

**Interpreting Results**:
- âœ“ **ALL TESTS PASSED** - Service is healthy
- âš  **Partial pass** - Some edge cases failed (usually acceptable)
- âœ— **TESTS FAILED** - Service has issues, check specific errors

**Common Failures & Solutions**:
1. **"Cannot connect to service"** â†’ Service not running, start with `./launcher.py`
2. **"CUDA not available"** â†’ Check nvidia-smi, install drivers
3. **"High latency"** â†’ First run is slow (model loading), ignore
4. **"Emotion misclassifications"** â†’ Normal for neutral/ambiguous text

**Debugging Workflow**:
1. Run `python scripts/test_service.py`
2. Check which tests failed
3. Look at specific error messages
4. Check service logs: `./launcher.py` (run manually)
5. Fix issues, re-run tests
6. Commit only when tests pass

---

## TECHNICAL DETAILS
- `airi-mods/docs/VBRIDGER_TESTING_RESULTS.md`
- `airi-mods/docs/PROJECT_STATUS.md`
- `CLAUDE.md` - Main project overview

---

## RECENT COMMITS (dev branch)

### Commit `4fd258c` - "test(ml-backend): Add comprehensive test suite for service validation"
**Date**: 2026-01-28  
**Changes**:
- âœ… Added CLI diagnostic tool (`scripts/test_service.py`)
- âœ… Added automated test runner (`scripts/run_tests.sh`)
- âœ… Added PyTest suite (`tests/test_api.py`) with 100+ tests
- âœ… Complete test documentation (`tests/README.md`)
- Tests cover: health, emotion accuracy, errors, performance, stability

### Commit `7b217ca` - "feat(ml-backend): Add Python-based ML inference service"
**Date**: 2026-01-28  
**Changes**:
- âœ… FastAPI server with emotion + BFA endpoints
- âœ… Service launcher with venv management
- âœ… Tauri integration (spawn/kill service)
- âœ… TypeScript HTTP client
- âœ… Complete service documentation

### Commit `c1c27c2` - "test(emotion): Force WASM mode and clear cache to test WebGPU corruption"
**Date**: 2026-01-28  
**Changes**:
- Discovered WebGPU produces garbage results (fear for everything)
- Verified WASM works correctly (joy 99% for happy text)
- Disabled WebGPU, using WASM as workaround

---

## NEXT IMMEDIATE ACTIONS

1. âœ… **Document everything** (this file)
2. âœ… **Create Python backend service structure**
3. âœ… **Implement emotion detection endpoint**
4. âœ… **Implement BFA phoneme alignment endpoint**
5. âœ… **Create Tauri service management**
6. âœ… **Update TypeScript client**
7. âœ… **Create comprehensive test suite**
8. â³ **Test end-to-end integration**
9. â³ **Update emotion-visual to use HTTP client**
10. â³ **Integrate BFA with VBridger**

---

## RESOURCES & REFERENCES

### Bournemouth Forced Aligner
- GitHub: https://github.com/tabahi/bournemouth-forced-aligner
- Paper: https://arxiv.org/abs/2509.23147
- PyPI: `pip install bournemouth-forced-aligner`

### Emotion Model
- HuggingFace: `j-hartmann/emotion-english-distilroberta-base`
- 7 emotions: anger, disgust, fear, joy, neutral, sadness, surprise

### ONNX Runtime WebGPU Issues
- GitHub Issue #18311: WebGPU incorrect output for SAM
- GitHub Issue #23403: Kokoro TTS WebGPU failures
- Root cause: Shader/operator bugs in WebGPU backend

### Project Documentation
- `PROJECT_BRIEFING.md` - Vision and philosophy
- `IMPLEMENTATION_PLAN.md` - Detailed roadmap
- `AIRI_ARCHITECTURE.md` - How AIRI works
- `CLAUDE.md` - Development guide

---

## CRITICAL FILES - DEBUGGING REFERENCE

**When debugging, START HERE:**

### ğŸ§ª Testing (ALWAYS RUN FIRST)
- `airi-mods/services/ml-backend/scripts/test_service.py` - **RUN THIS FIRST**
- `airi-mods/services/ml-backend/scripts/run_tests.sh` - Automated runner
- `airi-mods/services/ml-backend/tests/test_api.py` - PyTest suite
- `airi-mods/services/ml-backend/tests/README.md` - Test documentation

### ğŸ”§ ML Backend Service
- `airi-mods/services/ml-backend/src/main.py` - FastAPI server
- `airi-mods/services/ml-backend/launcher.py` - Service launcher
- `airi-mods/services/ml-backend/requirements.txt` - Dependencies
- `airi-mods/services/ml-backend/README.md` - Service documentation

### ğŸ­ Emotion Detection
- `airi-mods/packages/emotion-visual/src/ml-client.ts` - HTTP client
- `airi-mods/packages/emotion-visual/src/emotion-ml-detector.ts` - Old WASM code
- `airi-mods/packages/emotion-visual/src/plugin.ts` - Plugin integration

### ğŸ“š Documentation
- `airi-mods/docs/MASTER_CONTEXT.md` - **THIS FILE** (start here!)
- `airi-mods/docs/EMOTION_DETECTION_IMPLEMENTATION.md` - Phase 3 details
- `airi-mods/docs/VBRIDGER_TESTING_RESULTS.md` - Phase 2 results
- `CLAUDE.md` - Project overview and architecture

### ğŸ”§ Configuration/Scripts
- `airi-mods/scripts/install.sh` - Main installer (sets up everything)
- `airi-mods/services/ml-backend/scripts/install.sh` - ML backend setup

---

## HANDOVER NOTES FOR FUTURE AI ASSISTANTS

**If you're reading this, the context was likely wiped. Here's what you need to know:**

1. **We're building a VTuber AI assistant** on Project AIRI
2. **Current phase**: ML Backend Service is built, needs integration testing
3. **Why**: Browser ONNX is broken (WebGPU corruption)
4. **Architecture**: Tauri spawns Python service â†’ HTTP API â†’ models on GPU
5. **What's done**: Service, tests, launcher, client code all implemented
6. **What's next**: Test integration, update emotion-visual package, BFA lip-sync
7. **Key constraint**: RTX 3060 12GB VRAM

**IMMEDIATE ACTION - Run This:**
```bash
cd airi-mods/services/ml-backend
python scripts/test_service.py
```

**Check these files first**:
- This file (`MASTER_CONTEXT.md`) - **YOUR BIBLE**
- `airi-mods/services/ml-backend/README.md` - Service details
- `airi-mods/services/ml-backend/tests/README.md` - Testing guide
- Recent git commits on `dev` branch

**If tests fail** â†’ Debug service (check launcher.py, main.py)
**If tests pass** â†’ Service is healthy, work on integration

**Current branch**: `dev`
**Last known good state**: Emotion detection working with WASM
**Next goal**: Python backend service

---

## CONTACT & FEEDBACK

**Developer**: Raahat (User)  
**Preferences**: 
- In-depth technical discussions
- Clear reasoning for decisions
- Honest assessment of trade-offs
- Minimal formatting, no excessive enthusiasm

**Hardware**: RTX 3060 12GB VRAM, CachyOS Linux

---

*This document should be updated after every significant change. Future AI assistants: read this first before asking questions.*
